temp_df <- fit_new$data_frame
#Final Gradient
cv_df$max_grad[irow] <- max(abs(pars$diagnostics$final_gradient))
#Check whether hessian matrix is positive definite
cv_df$pdHess[irow] <- pars$SD$pdHess
#Extract the out-of-bag predicted NLL
cv_df$pred_nll[irow] <- fit_new$Report$pred_jnll
#Extract observed and predicted cpue of the withheld data
withheld_idx <- which(fit_new$data_list$PredTF_i == T)
obs_cpue <- (temp_df$b_i / temp_df$a_i)[withheld_idx]
pred_cpue <- fit_new$Report$D_i[withheld_idx]
#Calculate mean absolute error and root mean square error
cv_df$RMSE[irow] <- sqrt(mean((obs_cpue - pred_cpue)^2))
#Update progress
print(paste0("Done with: ", cv_df$species[irow], ", ",
ifelse(cv_df$depth[irow], "Depth, ", "No Depth, "),
"Fold Number ", cv_df$fold[irow]))
}
}
##################################################
####   Calculate how many of the folds converged with < 1E-5
##################################################
tidyr::spread(data = aggregate(max_grad ~ species + depth,
data = cv_df,
FUN = function(x) sum(x < 1E-4)),
key = "depth",
value = "max_grad")
##################################################
####  Calculate mean out-of-bag predicted NLL across folds
##################################################
prednll <- tidyr::spread(data = aggregate(pred_nll ~ species + depth,
data = cv_df,
FUN = function(x) round(mean(x)),
subset = max_grad < 1E-4),
key = "depth",
value = "pred_nll")
prednll$depth_in_model <- apply(X = prednll[, c("FALSE", "TRUE")],
MARGIN = 1,
FUN = function(x) c("FALSE", "TRUE")[which.min(x)] )
RMSE <- tidyr::spread(data = aggregate(RMSE ~ species + depth,
data = cv_df,
FUN = function(x) round(sqrt(mean(x^2))),
subset = max_grad < 1E-4),
key = "depth",
value = "RMSE")
prednll
RMSE
###############################################################################
## Project:       Cross-Validation Results
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   For each CV run, calculate relative root mean squre error of
##                density predictions
###############################################################################
rm(list = ls())
##################################################
####   Import Libraries
##################################################
library(VAST)
library(RANN)
library(tidyr)
VAST_dir <-  "C:/Users/Zack Oyafuso/Desktop/VAST_Runs/Single_Species/"
VAST_data_dir <-  "C:/Users/Zack Oyafuso/Documents/GitHub/MS_OM_GoA/"
github_dir <- "C:/Users/Zack Oyafuso/Documents/GitHub/Optimal_Allocation_GoA/"
##################################
## Import Strata Allocations and spatial grid and predicted density
##################################
load(paste0(github_dir, "data/Extrapolation_depths.RData"))
goa_data <- read.csv(paste0(VAST_data_dir, "data/GOA_multspp.csv"))
which_spp <- gsub(x = grep(x = dir(VAST_dir), pattern = "_depth", value = TRUE),
pattern = "_depth",
replacement = "")
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####  Install a forked version of the SamplingStrata Package from
####  zoyafuso-NOAA's Github page
####
####  Import other required packages
##################################################
library(devtools)
devtools::install_github(repo = "zoyafuso-NOAA/SamplingStrata")
library(SamplingStrata)
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories based on whether the optimization is being conducted
####        on a multi-species or single-species level
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- c("full_domain", "district")[2]
for (which_species in spp_idx_opt[10]) {
}
##################################################
####   Constants to set up based on which_domain and which_species
##################################################
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", which_species),
paste0("Y", which_species,
"_SQ_SUM"))]
names(frame)[6:7] <- paste0("Y", c("1", "1_SQ_SUM") )
n_dom <- length(unique(frame$domainvalue))
no_strata <- switch(which_domain,
"full_domain" = 10,
"district" = rep(5, n_dom))
result_dir = paste0(github_dir,
"results/", which_domain,
"/Single_Species_Optimization/",
common_names_all[which_species], '/')
result_dir
common_names_opt[10:12]
common_names_opt
common_names_eval
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####  Install a forked version of the SamplingStrata Package from
####  zoyafuso-NOAA's Github page
####
####  Import other required packages
##################################################
library(devtools)
devtools::install_github(repo = "zoyafuso-NOAA/SamplingStrata")
library(SamplingStrata)
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories based on whether the optimization is being conducted
####        on a multi-species or single-species level
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
##################################################
####   Create optimization scenarios
##################################################
scen <- data.frame(nstrata = c(3,5, 10,15),
which_domain = rep(c("district", "full_domain"), each = 2))
irow = 3
isample = 1
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- scen$which_domain[irow]
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", spp_idx_opt),
paste0("Y", spp_idx_opt,
"_SQ_SUM"))]
which_domain
##################################################
####   Create optimization scenarios
##################################################
scen <- data.frame(nstrata = c(3,5, 10,15),
which_domain = rep(c("district", "full_domain"), each = 2),
stringsAsFactors = F)
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- scen$which_domain[irow]
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", spp_idx_opt),
paste0("Y", spp_idx_opt,
"_SQ_SUM"))]
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt)] <-
paste0("Y", 1:ns_opt)
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt, "_SQ_SUM")] <-
paste0("Y", 1:ns_opt, "_SQ_SUM")
n_dom <- length(unique(frame$domainvalue))
temp_strata <- rep(x = scen$nstrata[irow], times = n_dom)
temp_strata
##Initial Condition
run <- 1
current_n <- 0
## Initiate CVs to be those calculated under SRS
srs_stats <- SamplingStrata::buildStrataDF(
dataset = cbind( subset(frame, select = -c(X1, X2)),
X1 = 1))
srs_n <- as.numeric(samples[isample] * table(frame$domainvalue) / n_cells)
srs_var <- as.matrix(srs_stats[, paste0("S", 1:ns_opt)])^2
srs_var <- sweep(x = srs_var,
MARGIN = 1,
STATS = (1 - srs_n / n_cells) / srs_n,
FUN = "*")
srs_cv <- sqrt(srs_var) / srs_stats[, paste0("M", 1:ns_opt)]
cv_constraints <- srs_cv
cv <- list()
for (spp in 1:ns_opt)
cv[[paste0("CV", spp)]] <-
as.numeric(switch(which_domain,
"district" = cv_constraints[, spp],
"full_domain" = cv_constraints[spp]))
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
cv
load(paste0(github_dir, "results/", which_domain,
"/Single_Species_Optimization/",
"optimization_knitted_results.RData"))
###############################################################################
## Project:       Spatiotemporal Survey Optimization
## Author:        Zack Oyafuso (zack.oyafuso@noaa.gov)
## Description:   Conduct SamplingStrata R package multispecies stratified
##                survey optimization
###############################################################################
rm(list = ls())
##################################################
####  Install a forked version of the SamplingStrata Package from
####  zoyafuso-NOAA's Github page
####
####  Import other required packages
##################################################
library(devtools)
devtools::install_github(repo = "zoyafuso-NOAA/SamplingStrata")
library(SamplingStrata)
library(sp)
library(RColorBrewer)
library(raster)
##################################################
####   Set up directories based on whether the optimization is being conducted
####        on a multi-species or single-species level
##################################################
which_machine <- c("Zack_MAC" = 1, "Zack_PC" = 2, "Zack_GI_PC" = 3)[3]
github_dir <- paste0(c("/Users/zackoyafuso/Documents",
"C:/Users/Zack Oyafuso/Documents",
"C:/Users/zack.oyafuso/Work")[which_machine],
"/GitHub/Optimal_Allocation_GoA/")
##################################################
####   Load Data
####   Load Population CVs for use in the thresholds
##################################################
load(paste0(github_dir, "/data/optimization_data.RData"))
load(paste0(github_dir, "/data/Extrapolation_depths.RData"))
##################################################
####   Create optimization scenarios
##################################################
scen <- data.frame(nstrata = c(3,5, 10,15),
which_domain = rep(c("district", "full_domain"), each = 2),
stringsAsFactors = FALSE)
irow = 3
isample = 1
##################################################
####   Constants to specify before doing optimization
##################################################
which_domain <- scen$which_domain[irow]
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", spp_idx_opt),
paste0("Y", spp_idx_opt,
"_SQ_SUM"))]
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt)] <-
paste0("Y", 1:ns_opt)
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt, "_SQ_SUM")] <-
paste0("Y", 1:ns_opt, "_SQ_SUM")
n_dom <- length(unique(frame$domainvalue))
temp_strata <- rep(x = scen$nstrata[irow], times = n_dom)
##Initial Condition
run <- 1
current_n <- 0
## Initiate CVs to be those calculated under SRS
srs_stats <- SamplingStrata::buildStrataDF(
dataset = cbind( subset(frame, select = -c(X1, X2)),
X1 = 1))
srs_n <- as.numeric(samples[isample] * table(frame$domainvalue) / n_cells)
srs_var <- as.matrix(srs_stats[, paste0("S", 1:ns_opt)])^2
srs_var <- sweep(x = srs_var,
MARGIN = 1,
STATS = (1 - srs_n / n_cells) / srs_n,
FUN = "*")
srs_cv <- sqrt(srs_var) / srs_stats[, paste0("M", 1:ns_opt)]
cv_constraints <- srs_cv
cv <- list()
for (spp in 1:ns_opt)
cv[[paste0("CV", spp)]] <-
as.numeric(switch(which_domain,
"district" = cv_constraints[, spp],
"full_domain" = cv_constraints[spp]))
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
load(paste0(github_dir, "results/", which_domain,
"/Single_Species_Optimization/",
"optimization_knitted_results.RData"))
ss_strs_pop_cv <- subset(x = settings,
subset = boat == isample,
select = c("species", paste0("cv_domain_",
1:n_dom)))
ss_strs_pop_cv
ss_strs_pop_cv <- ss_strs_pop_cv[match(common_names_opt,
ss_strs_pop_cv$species), ]
ss_strs_pop_cv
srs_cv
which_domain <- scen$which_domain[irow]
frame <- switch( which_domain,
"full_domain" = frame_all,
"district" = frame_district)[, c("domainvalue", "id",
"X1", "X2", "WEIGHT",
paste0("Y", spp_idx_opt),
paste0("Y", spp_idx_opt,
"_SQ_SUM"))]
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt)] <-
paste0("Y", 1:ns_opt)
names(frame)[names(frame) %in% paste0("Y", spp_idx_opt, "_SQ_SUM")] <-
paste0("Y", 1:ns_opt, "_SQ_SUM")
n_dom <- length(unique(frame$domainvalue))
temp_strata <- rep(x = scen$nstrata[irow], times = n_dom)
##Initial Condition
run <- 1
current_n <- 0
## Initiate CVs to be those calculated under SRS
srs_stats <- SamplingStrata::buildStrataDF(
dataset = cbind( subset(frame, select = -c(X1, X2)),
X1 = 1))
srs_n <- as.numeric(samples[isample] * table(frame$domainvalue) / n_cells)
srs_var <- as.matrix(srs_stats[, paste0("S", 1:ns_opt)])^2
srs_var <- sweep(x = srs_var,
MARGIN = 1,
STATS = (1 - srs_n / n_cells) / srs_n,
FUN = "*")
srs_cv <- sqrt(srs_var) / srs_stats[, paste0("M", 1:ns_opt)]
cv_constraints <- srs_cv
cv <- list()
for (spp in 1:ns_opt)
cv[[paste0("CV", spp)]] <-
as.numeric(switch(which_domain,
"district" = cv_constraints[, spp],
"full_domain" = cv_constraints[spp]))
cv[["DOM"]] <- 1:n_dom
cv[["domainvalue"]] <- 1:n_dom
cv <- as.data.frame(cv)
load(paste0(github_dir, "results/", which_domain,
"/Single_Species_Optimization/",
"optimization_knitted_results.RData"))
ss_strs_pop_cv <- subset(x = settings,
subset = boat == isample,
select = c("species", paste0("cv_domain_",
1:n_dom)))
ss_strs_pop_cv <- ss_strs_pop_cv[match(common_names_opt,
ss_strs_pop_cv$species), ]
ss_strs_pop_cv <- t(ss_strs_pop_cv[, -1])
colnames(ss_strs_pop_cv) <- common_names_opt
#Set wd for output files, create a directory if it doesn"t exist yet
temp_dir = paste0(github_dir, "results/", which_domain,
"/Multi_Species_Optimization/boat", isample,
"/Str", temp_strata[1], "/Run", run)
if(!dir.exists(temp_dir)) dir.create(temp_dir, recursive = T)
setwd(temp_dir)
#Run optimization
if(which_domain == "full_domain") par(mfrow = c(6,6),
mar = c(2,2,0,0))
solution <- optimStrata(method = "continuous",
errors = cv,
framesamp = frame,
iter = 5,
pops = 50,
elitism_rate = 0.1,
mut_chance = 1 / (temp_strata[1] + 1),
nStrata = temp_strata,
showPlot = T,
writeFiles = T)
## Organize result outputs
solution$aggr_strata$STRATO <- as.integer(solution$aggr_strata$STRATO)
solution$aggr_strata <-
solution$aggr_strata[order(solution$aggr_strata$DOM1,
solution$aggr_strata$STRATO), ]
sum_stats <- summaryStrata(solution$framenew,
solution$aggr_strata,
progress=FALSE)
sum_stats$stratum_id <- 1:nrow(sum_stats)
sum_stats$Population <- sum_stats$Population / n_years
sum_stats$wh <- sum_stats$Allocation / sum_stats$Population
sum_stats$Wh <- sum_stats$Population / n_cells
sum_stats <- cbind(sum_stats,
subset(x = solution$aggr_strata,
select = -c(STRATO, N, COST, CENS, DOM1, X1)))
sum_stats <- sum_stats[, c(10, 1:4, 15, 11:12, 6:9)]
plot_solution <-
switch(which_domain,
"full_domain" = solution$indices$X1,
"district" = as.factor(paste0(
"DOM", solution$framenew$DOMAINVALUE,
" STR", solution$framenew$STRATO))
)
plot_solution <- as.integer(plot_solution)
## Save Output
CV_constraints <- expected_CV(strata = solution$aggr_strata)
current_n <- sum(sum_stats$Allocation)
result_list <- list(solution = solution,
sum_stats = sum_stats,
CV_constraints = CV_constraints,
n = current_n,
sol_by_cell = plot_solution)
save(list = "result_list", file = "result_list.RData")
##Save a plot of the solution
goa <- sp::SpatialPointsDataFrame(
coords = Extrapolation_depths[, c("E_km", "N_km")],
data = data.frame(Str_no = plot_solution) )
goa_ras <- raster::raster(x = goa,
resolution = 5)
goa_ras <- raster::rasterize(x = goa,
y = goa_ras,
field = "Str_no")
png(filename = "solution.png",
width = 6,
height = 3,
units = "in",
res = 500)
par(mfrow = c(1, 1),
mar = c(1, 1, 1, 1))
plot(goa_ras,
axes = F,
asp = 1,
col = colorRampPalette(
brewer.pal(n = 11,
name = "Paired"))(length(unique(plot_solution)) ) )
rect(xleft = districts$W_UTM,
xright = districts$E_UTM,
ybottom = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = min),
ytop = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = max))
text(x = rowMeans(districts[, c("W_UTM", "E_UTM")]),
y = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = max),
labels = districts$district,
pos = 3)
box()
dev.off()
png(filename = "solution_with_stations.png",
width = 6,
height = 3,
units = "in",
res = 500)
par(mfrow = c(1, 1),
mar = c(1, 1, 1, 1))
plot(goa_ras,
axes = F,
asp = 1,
col = colorRampPalette(
brewer.pal(n = 11,
name = "Paired"))(length(unique(plot_solution)) ) )
rect(xleft = districts$W_UTM,
xright = districts$E_UTM,
ybottom = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = min),
ytop = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = max))
text(x = rowMeans(districts[, c("W_UTM", "E_UTM")]),
y = tapply(X = Extrapolation_depths$N_km,
INDEX = district_vals,
FUN = max),
labels = districts$district,
pos = 3)
box()
#Take a random sample based on the allocation and stratum
sample_vec <- c()
for(istrata in 1:nrow(sum_stats)) {
sample_vec <- c(sample_vec,
sample(x = which(plot_solution == istrata),
size = sum_stats$Allocation[istrata]) )
}
points(Extrapolation_depths[sample_vec, c("E_km", "N_km")],
pch = 16, cex = 0.5)
dev.off()
source('~/GitHub/Optimal_Allocation_GoA/analysis_scripts/Survey_Optimization.R', echo=TRUE)
